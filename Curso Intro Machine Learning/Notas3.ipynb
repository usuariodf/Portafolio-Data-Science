{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":38454,"sourceType":"datasetVersion","datasetId":2709}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Al final de este paso, comprenderá los conceptos de subajuste y sobreajuste y podrá aplicar estas ideas para hacer que sus modelos sean más precisos.\n\n## Experimentando con diferentes modelos\n\nAhora que dispone de una forma fiable de medir la precisión del modelo, puede experimentar con modelos alternativos y ver cuál ofrece las mejores predicciones. ¿Pero qué alternativas tienes para los modelos?\n\nPuede ver en la documentación de scikit-learn que el modelo de árbol de decisión tiene muchas opciones (más de las que querrá o necesitará durante mucho tiempo). Las opciones más importantes determinan la profundidad del árbol. Recuerde de la primera lección de este curso que la profundidad de un árbol es una medida de cuántas divisiones realiza antes de llegar a una predicción. Este es un árbol relativamente poco profundo.","metadata":{}},{"cell_type":"markdown","source":"En la práctica, no es raro que un árbol tenga 10 divisiones entre el nivel superior (todas las casas) y una hoja. A medida que el árbol se hace más profundo, el conjunto de datos se divide en hojas con menos casas. Si un árbol solo tuvo 1 división, divide los datos en 2 grupos. Si cada grupo se vuelve a dividir, obtendríamos 4 grupos de casas. Dividir cada uno de ellos nuevamente crearía 8 grupos. Si seguimos duplicando el número de grupos añadiendo más divisiones en cada nivel, tendremos 210\n   grupos de casas cuando lleguemos al décimo nivel. Son 1024 hojas.\n\nCuando dividimos las casas entre muchas hojas, también tenemos menos casas en cada hoja. Las hojas con muy pocas casas harán predicciones bastante cercanas a los valores reales de esas casas, pero pueden hacer predicciones muy poco confiables para datos nuevos (porque cada predicción se basa solo en unas pocas casas).\n\nEste es un fenómeno llamado sobreajuste, donde un modelo coincide casi perfectamente con los datos de entrenamiento, pero obtiene malos resultados en la validación y otros datos nuevos. Por otro lado, si hacemos que nuestro árbol sea muy poco profundo, no dividirá las casas en grupos muy distintos.\n\nEn un extremo, si un árbol divide las casas en sólo 2 o 4, cada grupo todavía tiene una amplia variedad de casas. Las predicciones resultantes pueden estar lejanas para la mayoría de las casas, incluso en los datos de entrenamiento (y también serán malas en la validación por la misma razón). Cuando un modelo no logra capturar distinciones y patrones importantes en los datos, por lo que funciona mal incluso en datos de entrenamiento, eso se denomina subajuste.\n\nDado que nos preocupamos por la precisión de los datos nuevos, que estimamos a partir de nuestros datos de validación, queremos encontrar el punto óptimo entre el desajuste y el sobreajuste.  ","metadata":{}},{"cell_type":"markdown","source":"### Ejemplo\nExisten algunas alternativas para controlar la profundidad del árbol y muchas permiten que algunas rutas a través del árbol tengan mayor profundidad que otras. Pero el argumento max_leaf_nodes proporciona una forma muy sensata de controlar el sobreajuste frente al desajuste. Cuantas más hojas permitimos que haga el modelo, más nos movemos del área de subajuste en el gráfico anterior al área de sobreajuste.\n\nPodemos usar una función de utilidad para ayudar a comparar puntuaciones MAE de diferentes valores para max_leaf_nodes:","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.tree import DecisionTreeRegressor\n\ndef get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T13:16:06.027875Z","iopub.execute_input":"2024-01-21T13:16:06.028280Z","iopub.status.idle":"2024-01-21T13:16:07.838755Z","shell.execute_reply.started":"2024-01-21T13:16:06.028246Z","shell.execute_reply":"2024-01-21T13:16:07.836797Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Los datos se cargan en train_X, val_X, train_y y val_y usando el código que ya has visto (y que ya has escrito).","metadata":{}},{"cell_type":"code","source":"# Data Loading Code Runs At This Point\nimport pandas as pd\n    \n# Load data\nmelbourne_file_path = '/kaggle/input/melbourne-housing-snapshot/melb_data.csv'\nmelbourne_data = pd.read_csv(melbourne_file_path) \n# Filter rows with missing values\nfiltered_melbourne_data = melbourne_data.dropna(axis=0)\n# Choose target and features\ny = filtered_melbourne_data.Price\nmelbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n                        'YearBuilt', 'Lattitude', 'Longtitude']\nX = filtered_melbourne_data[melbourne_features]\n\nfrom sklearn.model_selection import train_test_split\n\n# split data into training and validation data, for both features and target\ntrain_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T13:17:17.670217Z","iopub.execute_input":"2024-01-21T13:17:17.670701Z","iopub.status.idle":"2024-01-21T13:17:18.437479Z","shell.execute_reply.started":"2024-01-21T13:17:17.670660Z","shell.execute_reply":"2024-01-21T13:17:18.436283Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Podemos usar un bucle for para comparar la precisión de modelos creados con diferentes valores para max_leaf_nodes.","metadata":{}},{"cell_type":"code","source":"# compare MAE with differing values of max_leaf_nodes\nfor max_leaf_nodes in [5, 50, 490, 500, 510, 5000]:\n    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))","metadata":{"execution":{"iopub.status.busy":"2024-01-21T13:18:49.056800Z","iopub.execute_input":"2024-01-21T13:18:49.057215Z","iopub.status.idle":"2024-01-21T13:18:49.218761Z","shell.execute_reply.started":"2024-01-21T13:18:49.057184Z","shell.execute_reply":"2024-01-21T13:18:49.217411Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Max leaf nodes: 5  \t\t Mean Absolute Error:  347380\nMax leaf nodes: 50  \t\t Mean Absolute Error:  258171\nMax leaf nodes: 490  \t\t Mean Absolute Error:  243530\nMax leaf nodes: 500  \t\t Mean Absolute Error:  243495\nMax leaf nodes: 510  \t\t Mean Absolute Error:  244352\nMax leaf nodes: 5000  \t\t Mean Absolute Error:  255575\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Conclusión\nAquí está la conclusión: los modelos pueden sufrir cualquiera de los siguientes problemas:\n\nSobreajuste: capturar patrones espurios que no se repetirán en el futuro, lo que lleva a predicciones menos precisas, o\n\nDesajuste: no capturar patrones relevantes, lo que nuevamente conduce a predicciones menos precisas.\nUsamos datos de validación, que no se usan en el entrenamiento de modelos, para medir la precisión de un modelo candidato. Esto nos permite probar muchos modelos candidatos y quedarnos con el mejor.","metadata":{}}]}