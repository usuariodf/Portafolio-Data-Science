{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":38454,"sourceType":"datasetVersion","datasetId":2709}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Variables categóricas","metadata":{}},{"cell_type":"markdown","source":"Hay muchos datos no numéricos por ahí. Aquí se explica cómo usarlo para el aprendizaje automático.","metadata":{}},{"cell_type":"markdown","source":"## Introducción\nUna **variable categórica** toma sólo un número limitado de valores.\n\n* Considere una encuesta que le pregunte con qué frecuencia desayuna y ofrezca cuatro opciones: \"Nunca\", \"Rara vez\", \"La mayoría de los días\" o \"Todos los días\". En este caso, los datos son categóricos, porque las respuestas se clasifican en un conjunto fijo de categorías.\n* Si las personas respondieran a una encuesta sobre qué marca de automóvil poseen, las respuestas se clasificarían en categorías como \"Honda\", \"Toyota\" y \"Ford\". En este caso, los datos también son categóricos.\n\nRecibirá un error si intenta conectar estas variables en la mayoría de los modelos de aprendizaje automático en Python sin preprocesarlas primero. En este tutorial, compararemos tres enfoques que puede utilizar para preparar sus datos categóricos.","metadata":{}},{"cell_type":"markdown","source":"## Tres enfoques\n\n### 1) Eliminar variables categóricas\nEl enfoque más sencillo para tratar con variables categóricas es simplemente eliminarlas del conjunto de datos. Este enfoque sólo funcionará bien si las columnas no contienen información útil.","metadata":{}},{"cell_type":"markdown","source":"## 2) Codificación ordinal\nLa codificación ordinal asigna cada valor único a un número entero diferente.\n\nEste enfoque supone un orden de las categorías: \"Nunca\" (0) < \"Rara vez\" (1) < \"La mayoría de los días\" (2) < \"Todos los días\" (3).\n\nEsta suposición tiene sentido en este ejemplo, porque existe una clasificación indiscutible de las categorías. No todas las variables categóricas tienen un orden claro en los valores, pero nos referimos a aquellas que lo tienen como variables ordinales. Para los modelos basados en árboles (como árboles de decisión y bosques aleatorios), se puede esperar que la codificación ordinal funcione bien con variables ordinales.","metadata":{}},{"cell_type":"markdown","source":"### 3) Codificación One-Hot\nLa codificación one-hot crea nuevas columnas que indican la presencia (o ausencia) de cada valor posible en los datos originales. Para entender esto, trabajaremos con un ejemplo.\n\nEn el conjunto de datos original, \"Color\" es una variable categórica con tres categorías: \"Rojo\", \"Amarillo\" y \"Verde\". La codificación one-hot correspondiente contiene una columna para cada valor posible y una fila para cada fila del conjunto de datos original. Siempre que el valor original fuera \"Rojo\", ponemos un 1 en la columna \"Rojo\"; si el valor original era \"Amarillo\", ponemos un 1 en la columna \"Amarillo\", y así sucesivamente.\n\nA diferencia de la codificación ordinal, la codificación one-hot no supone un ordenamiento de las categorías. Por lo tanto, puede esperar que este enfoque funcione particularmente bien si no hay un orden claro en los datos categóricos (por ejemplo, \"Rojo\" no es ni más ni menos que \"Amarillo\"). Nos referimos a las variables categóricas sin una clasificación intrínseca como variables nominales.\n\nLa codificación one-hot generalmente no funciona bien si la variable categórica toma una gran cantidad de valores (es decir, generalmente no la usará para variables que toman más de 15 valores diferentes).","metadata":{}},{"cell_type":"markdown","source":"### Ejemplo\nComo en el tutorial anterior, trabajaremos con el conjunto de datos de Melbourne Housing.\n\nNo nos centraremos en el paso de carga de datos. En cambio, puedes imaginar que estás en un punto en el que ya tienes los datos de entrenamiento y validación en X_train, X_valid, y_train e y_valid.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Read the data\ndata = pd.read_csv('/kaggle/input/melbourne-housing-snapshot/melb_data.csv')\n\n# Separate target from predictors\ny = data.Price\nX = data.drop(['Price'], axis=1)\n\n# Divide data into training and validation subsets\nX_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n                                                                random_state=0)\n\n# Drop columns with missing values (simplest approach)\ncols_with_missing = [col for col in X_train_full.columns if X_train_full[col].isnull().any()] \nX_train_full.drop(cols_with_missing, axis=1, inplace=True)\nX_valid_full.drop(cols_with_missing, axis=1, inplace=True)\n\n# \"Cardinality\" means the number of unique values in a column\n# Select categorical columns with relatively low cardinality (convenient but arbitrary)\nlow_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n                        X_train_full[cname].dtype == \"object\"]\n\n# Select numerical columns\nnumerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n\n# Keep selected columns only\nmy_cols = low_cardinality_cols + numerical_cols\nX_train = X_train_full[my_cols].copy()\nX_valid = X_valid_full[my_cols].copy()","metadata":{"execution":{"iopub.status.busy":"2024-03-14T03:16:14.469814Z","iopub.execute_input":"2024-03-14T03:16:14.470300Z","iopub.status.idle":"2024-03-14T03:16:15.776356Z","shell.execute_reply.started":"2024-03-14T03:16:14.470249Z","shell.execute_reply":"2024-03-14T03:16:15.774987Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Echamos un vistazo a los datos de entrenamiento con el método head() a continuación.","metadata":{}},{"cell_type":"code","source":"X_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-14T03:16:25.801376Z","iopub.execute_input":"2024-03-14T03:16:25.802459Z","iopub.status.idle":"2024-03-14T03:16:25.837391Z","shell.execute_reply.started":"2024-03-14T03:16:25.802409Z","shell.execute_reply":"2024-03-14T03:16:25.835646Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"      Type Method             Regionname  Rooms  Distance  Postcode  Bedroom2  \\\n12167    u      S  Southern Metropolitan      1       5.0    3182.0       1.0   \n6524     h     SA   Western Metropolitan      2       8.0    3016.0       2.0   \n8413     h      S   Western Metropolitan      3      12.6    3020.0       3.0   \n2919     u     SP  Northern Metropolitan      3      13.0    3046.0       3.0   \n6043     h      S   Western Metropolitan      3      13.3    3020.0       3.0   \n\n       Bathroom  Landsize  Lattitude  Longtitude  Propertycount  \n12167       1.0       0.0  -37.85984    144.9867        13240.0  \n6524        2.0     193.0  -37.85800    144.9005         6380.0  \n8413        1.0     555.0  -37.79880    144.8220         3755.0  \n2919        1.0     265.0  -37.70830    144.9158         8870.0  \n6043        1.0     673.0  -37.76230    144.8272         4217.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Type</th>\n      <th>Method</th>\n      <th>Regionname</th>\n      <th>Rooms</th>\n      <th>Distance</th>\n      <th>Postcode</th>\n      <th>Bedroom2</th>\n      <th>Bathroom</th>\n      <th>Landsize</th>\n      <th>Lattitude</th>\n      <th>Longtitude</th>\n      <th>Propertycount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12167</th>\n      <td>u</td>\n      <td>S</td>\n      <td>Southern Metropolitan</td>\n      <td>1</td>\n      <td>5.0</td>\n      <td>3182.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>-37.85984</td>\n      <td>144.9867</td>\n      <td>13240.0</td>\n    </tr>\n    <tr>\n      <th>6524</th>\n      <td>h</td>\n      <td>SA</td>\n      <td>Western Metropolitan</td>\n      <td>2</td>\n      <td>8.0</td>\n      <td>3016.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>193.0</td>\n      <td>-37.85800</td>\n      <td>144.9005</td>\n      <td>6380.0</td>\n    </tr>\n    <tr>\n      <th>8413</th>\n      <td>h</td>\n      <td>S</td>\n      <td>Western Metropolitan</td>\n      <td>3</td>\n      <td>12.6</td>\n      <td>3020.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>555.0</td>\n      <td>-37.79880</td>\n      <td>144.8220</td>\n      <td>3755.0</td>\n    </tr>\n    <tr>\n      <th>2919</th>\n      <td>u</td>\n      <td>SP</td>\n      <td>Northern Metropolitan</td>\n      <td>3</td>\n      <td>13.0</td>\n      <td>3046.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>265.0</td>\n      <td>-37.70830</td>\n      <td>144.9158</td>\n      <td>8870.0</td>\n    </tr>\n    <tr>\n      <th>6043</th>\n      <td>h</td>\n      <td>S</td>\n      <td>Western Metropolitan</td>\n      <td>3</td>\n      <td>13.3</td>\n      <td>3020.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>673.0</td>\n      <td>-37.76230</td>\n      <td>144.8272</td>\n      <td>4217.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"A continuación, obtenemos una lista de todas las variables categóricas en los datos de entrenamiento.\n\nHacemos esto verificando el tipo de datos (o tipo d) de cada columna. El tipo de objeto indica que una columna tiene texto (en teoría, hay otras cosas que podrían ser, pero eso no es importante para nuestros propósitos). Para este conjunto de datos, las columnas con texto indican variables categóricas.","metadata":{}},{"cell_type":"code","source":"# Get list of categorical variables\ns = (X_train.dtypes == 'object')\nobject_cols = list(s[s].index)\n\nprint(\"Categorical variables:\")\nprint(object_cols)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T03:17:31.069353Z","iopub.execute_input":"2024-03-14T03:17:31.069757Z","iopub.status.idle":"2024-03-14T03:17:31.078530Z","shell.execute_reply.started":"2024-03-14T03:17:31.069729Z","shell.execute_reply":"2024-03-14T03:17:31.077001Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Categorical variables:\n['Type', 'Method', 'Regionname']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Definir función para medir la calidad de cada enfoque\n\nDefinimos una función score_dataset() para comparar los tres enfoques diferentes para tratar con variables categóricas. Esta función informa el error absoluto medio (MAE) de un modelo de bosque aleatorio. En general, queremos que el MAE sea lo más bajo posible.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# Function for comparing different approaches\ndef score_dataset(X_train, X_valid, y_train, y_valid):\n    model = RandomForestRegressor(n_estimators=100, random_state=0)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    return mean_absolute_error(y_valid, preds)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T03:19:40.810174Z","iopub.execute_input":"2024-03-14T03:19:40.810634Z","iopub.status.idle":"2024-03-14T03:19:41.128099Z","shell.execute_reply.started":"2024-03-14T03:19:40.810580Z","shell.execute_reply":"2024-03-14T03:19:41.127049Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Puntuación del método 1 (eliminar variables categóricas)\nQuitamos las columnas de objetos con el método select_dtypes().","metadata":{}},{"cell_type":"code","source":"drop_X_train = X_train.select_dtypes(exclude=['object'])\ndrop_X_valid = X_valid.select_dtypes(exclude=['object'])\n\nprint(\"MAE from Approach 1 (Drop categorical variables):\")\nprint(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))","metadata":{"execution":{"iopub.status.busy":"2024-03-14T03:19:46.301110Z","iopub.execute_input":"2024-03-14T03:19:46.301477Z","iopub.status.idle":"2024-03-14T03:19:52.044302Z","shell.execute_reply.started":"2024-03-14T03:19:46.301440Z","shell.execute_reply":"2024-03-14T03:19:52.042993Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"MAE from Approach 1 (Drop categorical variables):\n175703.48185157913\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Puntuación del método 2 (codificación ordinal)\n\nScikit-learn tiene una clase OrdinalEncoder que se puede utilizar para obtener codificaciones ordinales. Recorremos las variables categóricas y aplicamos el codificador ordinal por separado a cada columna.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\n\n# Make copy to avoid changing original data \nlabel_X_train = X_train.copy()\nlabel_X_valid = X_valid.copy()\n\n# Apply ordinal encoder to each column with categorical data\nordinal_encoder = OrdinalEncoder()\nlabel_X_train[object_cols] = ordinal_encoder.fit_transform(X_train[object_cols])\nlabel_X_valid[object_cols] = ordinal_encoder.transform(X_valid[object_cols])\n\nprint(\"MAE from Approach 2 (Ordinal Encoding):\") \nprint(score_dataset(label_X_train, label_X_valid, y_train, y_valid))","metadata":{"execution":{"iopub.status.busy":"2024-03-14T03:20:44.680732Z","iopub.execute_input":"2024-03-14T03:20:44.681183Z","iopub.status.idle":"2024-03-14T03:20:50.883688Z","shell.execute_reply.started":"2024-03-14T03:20:44.681152Z","shell.execute_reply":"2024-03-14T03:20:50.882547Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"MAE from Approach 2 (Ordinal Encoding):\n165936.40548390493\n","output_type":"stream"}]},{"cell_type":"markdown","source":"En la celda de código anterior, para cada columna, asignamos aleatoriamente cada valor único a un número entero diferente. Este es un enfoque común que es más sencillo que proporcionar etiquetas personalizadas; sin embargo, podemos esperar un aumento adicional en el rendimiento si proporcionamos etiquetas mejor informadas para todas las variables ordinales.","metadata":{}},{"cell_type":"markdown","source":"### Puntuación del método 3 (codificación One-Hot)\n\nUsamos la clase OneHotEncoder de scikit-learn para obtener codificaciones one-hot. Hay una serie de parámetros que se pueden utilizar para personalizar su comportamiento.\n\n* Configuramos handle_unknown='ignore' para evitar errores cuando los datos de validación contienen clases que no están representadas en los datos de entrenamiento, y\n* establecer sparse=False garantiza que las columnas codificadas se devuelvan como una matriz numerosa (en lugar de una matriz dispersa).\n\nPara usar el codificador, proporcionamos solo las columnas categóricas que queremos que se codifiquen. Por ejemplo, para codificar los datos de entrenamiento, proporcionamos X_train[object_cols]. (object_cols en la celda de código siguiente es una lista de los nombres de columnas con datos categóricos, por lo que X_train[object_cols] contiene todos los datos categóricos en el conjunto de entrenamiento).","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\n# Apply one-hot encoder to each column with categorical data\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\nOH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))\n\n# One-hot encoding removed index; put it back\nOH_cols_train.index = X_train.index\nOH_cols_valid.index = X_valid.index\n\n# Remove categorical columns (will replace with one-hot encoding)\nnum_X_train = X_train.drop(object_cols, axis=1)\nnum_X_valid = X_valid.drop(object_cols, axis=1)\n\n# Add one-hot encoded columns to numerical features\nOH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\nOH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n\n# Ensure all columns have string type\nOH_X_train.columns = OH_X_train.columns.astype(str)\nOH_X_valid.columns = OH_X_valid.columns.astype(str)\n\nprint(\"MAE from Approach 3 (One-Hot Encoding):\") \nprint(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))","metadata":{"execution":{"iopub.status.busy":"2024-03-14T03:24:18.939041Z","iopub.execute_input":"2024-03-14T03:24:18.939542Z","iopub.status.idle":"2024-03-14T03:24:25.797047Z","shell.execute_reply.started":"2024-03-14T03:24:18.939498Z","shell.execute_reply":"2024-03-14T03:24:25.795703Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"MAE from Approach 3 (One-Hot Encoding):\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"166089.4893009678\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## ¿Qué enfoque es mejor?\n\nEn este caso, eliminar las columnas categóricas (Método 1) obtuvo el peor resultado, ya que obtuvo la puntuación MAE más alta. En cuanto a los otros dos enfoques, dado que los puntajes MAE devueltos tienen un valor tan cercano, no parece haber ningún beneficio significativo para uno sobre el otro.\n\nEn general, la codificación one-hot (método 3) suele tener el mejor rendimiento, y eliminar las columnas categóricas (método 1) suele tener el peor rendimiento, pero varía según el caso.","metadata":{}},{"cell_type":"markdown","source":"### Conclusión\n\nEl mundo está lleno de datos categóricos. ¡Serás un científico de datos mucho más eficaz si sabes cómo utilizar este tipo de datos común!","metadata":{}}]}