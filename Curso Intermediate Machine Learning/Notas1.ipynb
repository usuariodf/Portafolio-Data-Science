{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":38454,"sourceType":"datasetVersion","datasetId":2709}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introducción\n¡Bienvenido al curso de aprendizaje automático intermedio!\n\nSi tienes experiencia en aprendizaje automático y te gustaría aprender cómo mejorar rápidamente la calidad de tus modelos, ¡estás en el lugar correcto! En este curso, acelerará su experiencia en aprendizaje automático aprendiendo a:\n\n* Abordar los tipos de datos que a menudo se encuentran en conjuntos de datos del mundo real (valores faltantes, variables categóricas).\n* Diseñar canales para mejorar la calidad de su código de aprendizaje automático.\n* Utilizar técnicas avanzadas para la validación de modelos (validación cruzada), construir modelos de última generación que se utilizan ampliamente para ganar competencias de Kaggle (XGBoost), y\n* Evite errores comunes e importantes en la ciencia de datos (fugas).\n\n \n\n## Requisitos previos\nEstá listo para este curso si ya ha creado un modelo de aprendizaje automático y está familiarizado con temas como la validación de modelos, el ajuste insuficiente y excesivo, y los bosques aleatorios. ","metadata":{}},{"cell_type":"markdown","source":"# 1. Valores faltantes","metadata":{}},{"cell_type":"markdown","source":"En este tutorial, aprenderá tres enfoques para lidiar con valores faltantes. Luego comparará la efectividad de estos enfoques en un conjunto de datos del mundo real. \n \nHay muchas formas en que los datos pueden terminar con valores faltantes. Por ejemplo,\n\n* Una casa de 2 dormitorios no incluirá el valor del tamaño de un tercer dormitorio.\n* Un encuestado puede optar por no compartir sus ingresos.\n\nLa mayoría de las bibliotecas de aprendizaje automático (incluida scikit-learn) dan un error si intentas construir un modelo usando datos con valores faltantes. Por lo tanto, deberá elegir una de las estrategias siguientes.","metadata":{}},{"cell_type":"markdown","source":"### 1. Una opción simple: eliminar columnas con valores faltantes\n\nLa opción más sencilla es eliminar las columnas con valores faltantes. A menos que falten la mayoría de los valores en las columnas eliminadas, el modelo pierde acceso a mucha información (¡potencialmente útil!) con este enfoque.\n\nComo ejemplo extremo, considere un conjunto de datos con 10.000 filas, donde a una columna importante le falta una sola entrada. ¡Este enfoque eliminaría la columna por completo!","metadata":{}},{"cell_type":"markdown","source":"### 2. Una mejor opción: la imputación\nLa imputación completa los valores faltantes con algún número. Por ejemplo, podemos completar el valor medio en cada columna.\n\nEl valor imputado no será exactamente correcto en la mayoría de los casos, pero generalmente conduce a modelos más precisos que los que se obtendrían si eliminara la columna por completo.","metadata":{}},{"cell_type":"markdown","source":"### 3. Una extensión de la imputación\n\nLa imputación es el enfoque estándar y normalmente funciona bien. Sin embargo, los valores imputados pueden estar sistemáticamente por encima o por debajo de sus valores reales (que no se recopilaron en el conjunto de datos). O las filas con valores faltantes pueden ser únicas de alguna otra manera. En ese caso, su modelo haría mejores predicciones al considerar qué valores faltaban originalmente.\n\nEn este enfoque, imputamos los valores faltantes, como antes. Y, además, para cada columna a la que le faltan entradas en el conjunto de datos original, agregamos una nueva columna que muestra la ubicación de las entradas imputadas.\n\nEn algunos casos, esto mejorará significativamente los resultados. En otros casos, no ayuda en absoluto.","metadata":{}},{"cell_type":"markdown","source":"## Ejemplo\nTrabajaremos con el conjunto de datos de Melbourne Housing. Nuestro modelo utilizará información como la cantidad de habitaciones y el tamaño del terreno para predecir el precio de la vivienda.\n\nNo nos centraremos en el paso de carga de datos. En cambio, puedes imaginar que estás en un punto en el que ya tienes los datos de entrenamiento y validación en X_train, X_valid, y_train e y_valid.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Load the data\ndata = pd.read_csv('/kaggle/input/melbourne-housing-snapshot/melb_data.csv')\n\n# Select target\ny = data.Price\n\n# To keep things simple, we'll use only numerical predictors\nmelb_predictors = data.drop(['Price'], axis=1)\nX = melb_predictors.select_dtypes(exclude=['object'])\n\n# Divide data into training and validation subsets\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,random_state=0)","metadata":{"execution":{"iopub.status.busy":"2024-02-11T22:22:26.515643Z","iopub.execute_input":"2024-02-11T22:22:26.516166Z","iopub.status.idle":"2024-02-11T22:22:26.605275Z","shell.execute_reply.started":"2024-02-11T22:22:26.516130Z","shell.execute_reply":"2024-02-11T22:22:26.603987Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Definir función para medir la calidad de cada enfoque\n\nDefinimos una función score_dataset() para comparar diferentes enfoques para tratar con valores faltantes. Esta función informa el error absoluto medio (MAE) de un modelo de bosque aleatorio.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# Function for comparing different approaches\ndef score_dataset(X_train, X_valid, y_train, y_valid):\n    model = RandomForestRegressor(n_estimators=10, random_state=0)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    return mean_absolute_error(y_valid, preds)","metadata":{"execution":{"iopub.status.busy":"2024-02-11T22:22:29.553966Z","iopub.execute_input":"2024-02-11T22:22:29.554418Z","iopub.status.idle":"2024-02-11T22:22:29.561343Z","shell.execute_reply.started":"2024-02-11T22:22:29.554383Z","shell.execute_reply":"2024-02-11T22:22:29.560118Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Puntuación del método 1 (eliminar columnas con valores faltantes)\nDado que estamos trabajando con conjuntos de entrenamiento y validación, tenemos cuidado de eliminar las mismas columnas en ambos DataFrames.","metadata":{}},{"cell_type":"code","source":"# Get names of columns with missing values\ncols_with_missing = [col for col in X_train.columns\n                     if X_train[col].isnull().any()]\n\n# Drop columns in training and validation data\nreduced_X_train = X_train.drop(cols_with_missing, axis=1)\nreduced_X_valid = X_valid.drop(cols_with_missing, axis=1)\n \n\nprint(\"MAE from Approach 1 (Drop columns with missing values):\")\nprint(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))","metadata":{"execution":{"iopub.status.busy":"2024-02-11T22:22:37.336284Z","iopub.execute_input":"2024-02-11T22:22:37.336783Z","iopub.status.idle":"2024-02-11T22:22:37.910826Z","shell.execute_reply.started":"2024-02-11T22:22:37.336743Z","shell.execute_reply":"2024-02-11T22:22:37.909643Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"MAE from Approach 1 (Drop columns with missing values):\n183550.22137772635\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Puntuación del Método 2 (Imputación)\nA continuación, usamos SimpleImputer para reemplazar los valores faltantes con el valor medio en cada columna.\n\nAunque es simple, completar el valor medio generalmente funciona bastante bien (pero esto varía según el conjunto de datos). Si bien los estadísticos han experimentado con formas más complejas de determinar los valores imputados (como la imputación de regresión, por ejemplo), las estrategias complejas generalmente no brindan ningún beneficio adicional una vez que se conectan los resultados a modelos sofisticados de aprendizaje automático.","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\n# Imputation\nmy_imputer = SimpleImputer()\nimputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\nimputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n \n\n# Imputation removed column names; put them back\nimputed_X_train.columns = X_train.columns\nimputed_X_valid.columns = X_valid.columns\n\n\n\nprint(\"MAE from Approach 2 (Imputation):\")\nprint(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))","metadata":{"execution":{"iopub.status.busy":"2024-02-11T22:22:43.947746Z","iopub.execute_input":"2024-02-11T22:22:43.948198Z","iopub.status.idle":"2024-02-11T22:22:44.676648Z","shell.execute_reply.started":"2024-02-11T22:22:43.948166Z","shell.execute_reply":"2024-02-11T22:22:44.675131Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"MAE from Approach 2 (Imputation):\n178166.46269899711\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Vemos que el Método 2 tiene un MAE más bajo que el Método 1, por lo que el Método 2 funcionó mejor en este conjunto de datos.","metadata":{}},{"cell_type":"markdown","source":"### Puntuación del método 3 (una extensión de la imputación)\nA continuación, imputamos los valores faltantes y al mismo tiempo realizamos un seguimiento de qué valores se imputaron.","metadata":{}},{"cell_type":"code","source":"# Make copy to avoid changing original data (when imputing)\nX_train_plus = X_train.copy()\nX_valid_plus = X_valid.copy()\n\n# Make new columns indicating what will be imputed\nfor col in cols_with_missing:\n    X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n    X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n    \n \n\n# Imputation\nmy_imputer = SimpleImputer()\nimputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\nimputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))\n \n\n# Imputation removed column names; put them back\nimputed_X_train_plus.columns = X_train_plus.columns\nimputed_X_valid_plus.columns = X_valid_plus.columns\n\nprint(\"MAE from Approach 3 (An Extension to Imputation):\")\nprint(score_dataset(imputed_X_train_plus, imputed_X_valid_plus, y_train, y_valid))","metadata":{"execution":{"iopub.status.busy":"2024-02-11T22:27:05.574386Z","iopub.execute_input":"2024-02-11T22:27:05.574810Z","iopub.status.idle":"2024-02-11T22:27:06.365262Z","shell.execute_reply.started":"2024-02-11T22:27:05.574779Z","shell.execute_reply":"2024-02-11T22:27:06.364299Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"MAE from Approach 3 (An Extension to Imputation):\n178927.503183954\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Como podemos ver, el Método 3 tuvo un desempeño ligeramente peor que el Método 2.\n\n### Entonces, ¿por qué la imputación funcionó mejor que eliminar las columnas?\nLos datos de entrenamiento tienen 10864 filas y 12 columnas, donde tres columnas contienen datos faltantes. Para cada columna, faltan menos de la mitad de las entradas. Por lo tanto, eliminar las columnas elimina mucha información útil, por lo que tiene sentido que la imputación funcione mejor.","metadata":{}},{"cell_type":"code","source":"# Shape of training data (num_rows, num_columns)\nprint(X_train.shape)\n\n# Number of missing values in each column of training data\nmissing_val_count_by_column = (X_train.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column > 0])","metadata":{"execution":{"iopub.status.busy":"2024-02-11T22:28:39.143560Z","iopub.execute_input":"2024-02-11T22:28:39.144963Z","iopub.status.idle":"2024-02-11T22:28:39.156431Z","shell.execute_reply.started":"2024-02-11T22:28:39.144907Z","shell.execute_reply":"2024-02-11T22:28:39.154833Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"(10864, 12)\nCar               49\nBuildingArea    5156\nYearBuilt       4307\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Conclusión\nComo es común, imputar valores faltantes (en los Métodos 2 y 3) arrojó mejores resultados, en comparación con cuando simplemente eliminamos las columnas con valores faltantes (en el Método 1).","metadata":{}}]}